{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[registered tool] {'description': 'Generates a random number x, s.t. range[0] <= x < range[1]',\n",
      " 'name': 'random_number_generator',\n",
      " 'params': [{'description': 'The random seed used by the generator',\n",
      "             'name': 'seed',\n",
      "             'required': True,\n",
      "             'type': 'int'},\n",
      "            {'description': 'The range of the generated numbers',\n",
      "             'name': 'range',\n",
      "             'required': True,\n",
      "             'type': 'tuple[int, int]'}]}\n",
      "[registered tool] {'description': 'Get the current weather for `city_name`',\n",
      " 'name': 'get_weather',\n",
      " 'params': [{'description': 'The name of the city to be queried',\n",
      "             'name': 'city_name',\n",
      "             'required': True,\n",
      "             'type': 'str'}]}\n",
      "[registered tool] {'description': '获取经营指定产品的公司',\n",
      " 'name': 'get_company_operating_the_given_product',\n",
      " 'params': [{'description': '产品',\n",
      "             'name': 'product',\n",
      "             'required': True,\n",
      "             'type': 'str'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lc/.conda/envs/pytorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from conversation import postprocess_text, preprocess_text, Conversation, Role\n",
    "from tool_registry import dispatch_tool, get_tools\n",
    "from transformers import AutoModel, AutoTokenizer, BertModel\n",
    "from transformers.generation.utils import LogitsProcessorList, StoppingCriteriaList, GenerationConfig, ModelOutput\n",
    "from transformers.generation.logits_process import LogitsProcessor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = Role.USER\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = '经营电池的公司有哪些'\n",
    "history.append(Conversation(role, prompt_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conversation(role=<Role.USER: 2>, content='经营电池的公司有哪些', tool=None, image=None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = preprocess_text(\n",
    "    None,\n",
    "    tools,\n",
    "    history,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOL_PROMPT = 'Answer the following questions as best as you can. You have access to the following tools:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [{\n",
    "    'role': 'system',\n",
    "    'content': TOOL_PROMPT,\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history[0]['tools'] = tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'Answer the following questions as best as you can. You have access to the following tools:',\n",
       "  'tools': {'random_number_generator': {'name': 'random_number_generator',\n",
       "    'description': 'Generates a random number x, s.t. range[0] <= x < range[1]',\n",
       "    'params': [{'name': 'seed',\n",
       "      'description': 'The random seed used by the generator',\n",
       "      'type': 'int',\n",
       "      'required': True},\n",
       "     {'name': 'range',\n",
       "      'description': 'The range of the generated numbers',\n",
       "      'type': 'tuple[int, int]',\n",
       "      'required': True}]},\n",
       "   'get_weather': {'name': 'get_weather',\n",
       "    'description': 'Get the current weather for `city_name`',\n",
       "    'params': [{'name': 'city_name',\n",
       "      'description': 'The name of the city to be queried',\n",
       "      'type': 'str',\n",
       "      'required': True}]},\n",
       "   'get_company_operating_the_given_product': {'name': 'get_company_operating_the_given_product',\n",
       "    'description': 'Get the companies that operates the given product',\n",
       "    'params': [{'name': 'product',\n",
       "      'description': 'The given product',\n",
       "      'type': 'str',\n",
       "      'required': True}]}}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = history[-1].content\n",
    "role = str(history[-1].role).removeprefix('<|').removesuffix('|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/home/lc/projects/pretrained_models/chatglm3-6b'\n",
    "DEVICE = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp, his = model.chat(tokenizer=tokenizer, query=query, history=chat_history, role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_company_operating_the_given_product',\n",
       " 'parameters': {'product': '电池'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = dispatch_tool(resp['name'], resp['parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tool_registry import _TOOL_HOOKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = _TOOL_HOOKS[resp['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': '电池'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp['parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['电池', '新能源']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call(**resp['parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['电池', '新能源']\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvalidScoreLogitsProcessor(LogitsProcessor):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        if torch.isnan(scores).any() or torch.isinf(scores).any():\n",
    "            scores.zero_()\n",
    "            scores[..., 5] = 5e4\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length: int = 8192\n",
    "num_beams=1\n",
    "do_sample=True\n",
    "top_p=0.8\n",
    "temperature=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_processor = LogitsProcessorList()\n",
    "logits_processor.append(InvalidScoreLogitsProcessor())\n",
    "gen_kwargs = {\n",
    "    \"max_length\": max_length,\n",
    "    \"num_beams\": num_beams,\n",
    "    \"do_sample\": do_sample,\n",
    "    \"top_p\": top_p,\n",
    "    \"temperature\": temperature,\n",
    "    \"logits_processor\": logits_processor\n",
    "}\n",
    "inputs = tokenizer.build_chat_input(query, history=chat_history, role=role)\n",
    "inputs = inputs.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token_id = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.get_command(\"<|user|>\"),\n",
    "    tokenizer.get_command(\"<|observation|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(**inputs, **gen_kwargs, eos_token_id=eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = outputs.tolist()[0][len(inputs[\"input_ids\"][0]):-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tokenizer.decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append({\"role\": role, \"content\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata, content = response.split(\"\\n\", maxsplit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append({\"role\": \"assistant\", \"metadata\": metadata, \"content\": content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\\n\".join(content.split(\"\\n\")[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_call(**kwargs):\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = eval(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = {\"name\": metadata.strip(), \"parameters\": parameters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = dispatch_tool(content['name'], content['parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.append(\n",
    "    Conversation(Role.TOOL, \"```python\\ntool_call(city_name='北京')\\n```\",\n",
    "                 'get_weather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.append(Conversation(Role.OBSERVATION, observation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history[-1].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
